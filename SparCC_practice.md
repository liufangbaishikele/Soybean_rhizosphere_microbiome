#   SparCC 

#### SparCC [source depository](https://bitbucket.org/yonatanf/sparcc)is a python module for computing correlations
in compositional data (16S, metagenomics, etc').

# Installation to Beacon server
* Download the source code from [download site](https://bitbucket.org/yonatanf/sparcc/get/05f4d3f31d77.zip) to my directory
```
cd /lustre/medusa/fliu21/SparCC
wget https://bitbucket.org/yonatanf/sparcc/get/05f4d3f31d77.zip
```
Then **unzip** the directory and **change file name** to SparCC\_bitbucket

```
unzip 05f4d3f31d77.zip
mv yonatanf-sparcc-05f4d3f31d77/ SparCC_bitbucket
rm 05f4d3f31d77.zip
```
* I have installed Panda package in my ``anaconda2/bin`` directory, so I will set up the PATH to this 

```
expo
rt PATH=/lustre/medusa/fliu21/anaconda2/bin:$PATH
```
* As python has already installed on beacon server, I just load the environment by
```
module load python/3.6.1
```
* Now type in ``python SparCC.py -h`` inside of ``SparCC_bitbucket`` directory, you will see below manual

```
Example: python SparCC.py example/fake_data.txt -i 20 --cor_file=example/basis_corr/cor_mat_sparcc.out

Options:
  -h, --help            show this help message and exit
  -c COR_FILE, --cor_file=COR_FILE
                        File to which correlation matrix will be written.
  -v COV_FILE, --cov_file=COV_FILE
                        File to which covariance matrix will be written.
  -a ALGO, --algo=ALGO  Name of algorithm used to compute correlations (SparCC
                        (default) | pearson | spearman | kendall)
  -i ITER, --iter=ITER  Number of inference iterations to average over (20
                        default).
  -x XITER, --xiter=XITER
                        Number of exclusion iterations to remove strongly
                        correlated pairs (10 default).
  -t TH, --thershold=TH
                        Correlation strength exclusion threshold (0.1
                        default).

```
Look into the example file, the input out table is formated with **rows being OTUs** from 1 to 50; **columns are sample** names from 1 to 200 samples

## SparCC at class level using phyloseq-based OTU cluster data (including .shared and .cons.taxonomy)

* Prepare table format in R using phyloseq package
  1. Generate class level phyloseq using all samples
  2. Subset samples to include only Ag rhizosphere samples
  3. Filter off classes that has maximum abundance smaller than 20
  4. transform absolute abundance to relative abundance.
  5. Comebine tax\_table and otu\_table
  6. Write out ``r_filter_Ag_Rhi_otu_and_tax_table.csv`` table to local
  
* Upload table to beacon server /lustre/medusa/fliu21/SparCC directory
* change csv file to txt file using 

```
sed 's/,/\t/g' r_filter_Ag_Rhi_otu_and_tax_table.csv > r_filter_Ag_Rhi_otu_and_tax_table.txt
```

* Inside of ``AgRhi_SparCC `` directory, create ``basis_corr`` and ``pvals`` folder
* Go back to ``/lustre/medusa/fliu21/SparCC`` directory

* RUN SparCC.py command

```
python SparCC.py AgRhi_SparCC/r_filter_Ag_Rhi_otu_and_tax_table.txt  -i 20 --cor_file=AgRhi_SparCC/basis_corr/AgRhi_cor_sparcc.txt -a SparCC
```
   1. Here -i means the number of inference iterations to avaerage over. -a means the algrithm for calculate correaction, which include SparCC, Peason, Spearman and Kendall.
   
   
* Now make shuffled datasets for calculating p value using ``MakeBootstraps.py`` function.

   1. Here are the help file of ``MakeBootstraps`` (documentation)
   
```
   Usage: Make n simulated datasets used to get pseudo p-values.
Simulated datasets are generated by assigning each OTU in each sample an abundance that is randomly drawn (w. replacement) from the abundances of the OTU in all samples.
Simulated datasets are either written out as txt files. 

Usage:   python MakeBootstraps.py counts_file [options]
Example: python MakeBootstraps.py example/fake_data.txt -n 5 -t permutation_#.txt -p example/pvals/

Options:
  -h, --help            show this help message and exit
  -n N                  Number of simulated datasets to create (100 default).
  -t PERM_TEMPLATE, --template=PERM_TEMPLATE
                        The template for the permuted data file names. Should
                        not include the path, which is specified using the -p
                        option. The iteration number is indicated with a "#".
                        For example: 'permuted/counts.permuted_#.txt'If not
                        provided a '.permuted_#.txt' suffix will be added to
                        the counts file name.
  -p OUTPATH, --path=OUTPATH
                        The path to which permuted data will be written. If
                        not provided files will be written to the cwd.
```

2. My code
   
* I created a subfolder ``bootstrap_simulation`` inside of pval folder to hold the simulated dataset

* Run command 
     
     ```
     python MakeBootstraps.py  AgRhi_SparCC/r_filter_Ag_Rhi_otu_and_tax_table.txt -n 200  
     --template=AgRhi_otu_count_permutation#.txt --path=AgRhi_SparCC/pvals/bootstrap_simulation/
     ```
     
* Part of the simulated output file by ``MakeBootstraps.py``
     
     ```
     AgRhi_otu_count_permutation0.txt    
     AgRhi_otu_count_permutation160.txt  
     AgRhi_otu_count_permutation40.txt
     AgRhi_otu_count_permutation100.txt  
     AgRhi_otu_count_permutation161.txt  
     AgRhi_otu_count_permutation41.txt
     AgRhi_otu_count_permutation101.txt  
     AgRhi_otu_count_permutation162.txt 
     ```
     
* Calculate SparCC using shuffled dataset with exactly the same parameter set up when calculate the former data set. Name all the output files consistently, numbered sequentially, and with a '.txt' extension.
   
   
  **NOTE** If I only calculate p\_value using one shuffled dataset, the command will like below
   
   ```
   python SparCC.py AgRhi_SparCC/pvals/bootstrap_simulation/AgRhi_otu_count_permutation0.txt -i 20 --cor_file=AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation0_corr.txt -a SparCC
   
   ```
   
  **As I have 200 bootstrap permutations, I will write a for loop to do this work**
   
   1. Creat a script
   ``nano calculate_SparCC_on_simulated_dataset.sge``
   
   ```
   for ((i=0;i<=199;i++))
   do
     echo $i
     python SparCC.py AgRhi_SparCC/pvals/bootstrap_simulation/AgRhi_otu_count_permutation$i.txt -i 20 --cor_file=AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation$i_corr.txt -a SparCC
     
   done
   ```
   **NOTE** The above for loop did not do the work for 200 samples. It just generated one file named ``AgRhi_bootstrap_permutation``
   
 Â  * Told by Miriam, the variable $i need double quoted when named together with underscore. Because this will separate the content between`` _``. So always double quote when name a file with variable.
   * Function double cite - echo (echo path/filename\_"$i") 
   
   * Here are the right script
   
   ```
   for ((i=0;i<=199;i++))
   do
     echo $i
     python SparCC.py AgRhi_SparCC/pvals/bootstrap_simulation/AgRhi_otu_count_permutation"$i".txt -i 20 --cor_file=AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation"$i"_corr.txt -a SparCC
     
   done
   ```
   
   2. Change script to excutable
   ``chmod u+x AgRhi_calculate_SparCC_on_simulated_dataset.sge``
   
   3. RUN ``AgRhi_calculate_SparCC_on_simulated_dataset.sge``script
   
   ```
   sh AgRhi_calculate_SparCC_on_simulated_dataset.sge
   ```
   4. It will take a while to finish SparCC calculation using 200 simulated datasets.
   
* Now ready to do one\_sided 
```
python PseudoPvals.py AgRhi_SparCC/basis_corr/AgRhi_cor_sparcc.txt AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation#_corr.txt 200 -o AgRhi_SparCC/pvals/AgRhi_one_sided_pvalue.txt -t one_sided
```
* two\_sided p\_value calculattion

```
python PseudoPvals.py AgRhi_SparCC/basis_corr/AgRhi_cor_sparcc.txt AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation#_corr.txt 200 -o AgRhi_SparCC/pvals/AgRhi_two_sided_pvalue.txt -t two_sided
```
 5. Change both SparCC correlation matrix and two\_sided p\_value from *txt* to *csv* format and transfer to local computer and upload to R to start network visualization using igraph package.
 
 ```
 sed 's/\t/,/g' ForRhi_two_sided_pvalue.txt > ForRhi_two_sided_pvalue.csv
 cd /lustre/medusa/fliu21/SparCC/ForRhi_SparCC/basis_corr
 sed 's/\t/,/g' ForRhi_cor_sparcc.txt > ForRhi_cor_sparcc.csv
 ```
 
------------------------------------------------------
## SparCC analysis on soybean genotype project
------------------------------------------------------

1. Prepare genus level OTU table and taxonomy on ACF

  ``/lustre/haven/gamma/staton/projects/soybean_rhizosphere/05_final_run/16S_cultivar_proj/analysis/002_mothur_analysis/rarefied_shared_SparCC``
  * copy genus level OTU table created by mothur to this current SparCC directory 
  * Subset shared file to Ag_soil, Ag_Rhi, For_soil, For_Rhi.
  * Rarefy shared file to 19023 sequencing depth
  * Remove any genera that with total reads smaller than 50.
  * Write out genus OTU table to local computer ``/Users/fangliu/Documents/2016_cultivar_project/R_analysis/SparCC_2nd``
 
2. Intergrating OTU count table and taxonomy table with row names corresponding to genus name and write out to local computer.
3. Format the csv file to below format.
```
Genus	                                     Ag_B_1     	Ag_B_10      	Ag_B_11 ...
Bacteria_unclassified	                      3762	        4006	        4160
Planctomycetaceae_unclassified	             480	         800	         921
Spartobacteria_genera_incertae_sedis	       179	         209	         194
Burkholderia	                                1	            12	          24
.
.
.

```
4. Upload above csv file to ACF and substitude comma with tab.
5. Running SparCC to calculate SparCC correlation matrix as well as p_value matrix. Below is the job script:
```
python SparCC.py Ag_Rhi/Ag_Rhi_genus_SparCC.txt  -i 20 --cor_file=Ag_Rhi/basis_corr/Ag_Rhi_genus_cor_sparcc.txt -a SparCC
python MakeBootstraps.py  Ag_Rhi/Ag_Rhi_genus_SparCC.txt -n 200 --template=Ag_Rhi_genus_otu_count_permutation#.txt --path=Ag_Rhi/pvals/bootstrap_simulation/

for ((i=0;i<=199;i++))
do
  echo $i
  python SparCC.py Ag_Rhi/pvals/bootstrap_simulation/Ag_Rhi_genus_otu_count_permutation"$i".txt -i 20 --cor_file=Ag_Rhi/pvals/bootstrap_corr/Ag_Rhi_genus_bootstrap_permutation"$i"_corr.txt -a SparCC
done

python PseudoPvals.py Ag_Rhi/basis_corr/Ag_Rhi_genus_cor_sparcc.txt Ag_Rhi/pvals/bootstrap_corr/Ag_Rhi_genus_bootstrap_permutation#_corr.txt 200 -o Ag_Rhi/pvals/Ag_Rhi_genus_two_sided_pvalue.txt -t two_sided
```
**NOTE**:  

  * During the above calculation process, SparCC correlation are averate based on 20 iterations.
  * p_value matrix are calculate based on 200 bootstraping process. Basically, during the bootstraping process, it genearted 200 sets of simulated genus count matrix from original genus count matrix. By comparing the SparCC correlation matrix generated using 200 simulated datasets with that generated from our original dataset, it will give the p_value information.
  
  
6. Convert SparCC correlation matrix (txt) and p_value matrix (txt) to csv file

7. Transfer data from ACF to local computer and start network analysis in R using igraph package. In terms of igraph network analysis, refer to this [tutorial](http://kateto.net/networks-r-igraph)























